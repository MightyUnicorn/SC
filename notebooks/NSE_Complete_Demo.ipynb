{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ebb2748",
   "metadata": {},
   "source": [
    "# NSE Analytics Platform - Complete Demo\n",
    "\n",
    "## üéØ Professional Data Platform Demonstration\n",
    "\n",
    "This notebook demonstrates a comprehensive NSE (National Stock Exchange) data analytics platform with:\n",
    "\n",
    "### üìä Core Capabilities\n",
    "- **Data Fetching & Storage**: Automated collection from Yahoo Finance with quality validation\n",
    "- **Interactive Analytics**: GUI-based returns and correlation analysis\n",
    "- **Data Quality Management**: Comprehensive validation and error handling\n",
    "- **Professional Presentation**: Clean, demo-ready code\n",
    "\n",
    "### üèóÔ∏è Technical Architecture\n",
    "- **Database**: SQLite with normalized schema and constraints\n",
    "- **Data Processing**: Pandas with vectorized operations\n",
    "- **User Interface**: Interactive widgets with real-time feedback\n",
    "- **Quality Assurance**: Multi-layer validation and error handling\n",
    "\n",
    "### üìà Business Value\n",
    "- **Risk Management**: Correlation analysis for portfolio diversification\n",
    "- **Performance Tracking**: Monthly/yearly returns monitoring\n",
    "- **Data Integrity**: Comprehensive quality validation\n",
    "- **Scalability**: Modular design for easy extension\n",
    "\n",
    "---\n",
    "\n",
    "**Author**: KO + GitHub Copilot  \n",
    "**Purpose**: Interview demonstration and portfolio showcase  \n",
    "**Date**: July 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71016dbb",
   "metadata": {},
   "source": [
    "## üéØ Demo Usage Instructions\n",
    "\n",
    "### Step 1: Data Fetching\n",
    "1. **Run the first cell** to fetch and store NSE data\n",
    "2. **Review the output** for successful/failed indices\n",
    "3. **Check database statistics** (total records, failed tickers)\n",
    "\n",
    "### Step 2: Returns Analysis\n",
    "1. **Use the Returns Analysis tab** in the dashboard above\n",
    "2. **Select indices** (single for monthly breakdown, multiple for yearly comparison)\n",
    "3. **Choose time periods** (years of interest)\n",
    "4. **Click \"Calculate Returns\"** to generate color-coded matrices\n",
    "\n",
    "### Step 3: Correlation Analysis\n",
    "1. **Switch to Correlation Matrix tab**\n",
    "2. **Configure parameters**:\n",
    "   - Indices selection\n",
    "   - Time interval (Daily/Monthly)\n",
    "   - Price type (Open/High/Low/Close)\n",
    "   - Date range\n",
    "3. **Click \"Calculate Correlation\"** for correlation matrix with quality reports\n",
    "\n",
    "### Key Features Demonstrated\n",
    "- ‚úÖ **Professional Code Quality**: Clean, documented, maintainable\n",
    "- ‚úÖ **Data Engineering**: ETL pipeline with validation\n",
    "- ‚úÖ **Interactive Analytics**: User-friendly GUI with real-time feedback\n",
    "- ‚úÖ **Error Handling**: Comprehensive exception management\n",
    "- ‚úÖ **Business Value**: Risk management and performance tracking tools\n",
    "\n",
    "---\n",
    "\n",
    "**This notebook demonstrates production-ready data platform development suitable for financial analysis and portfolio management applications.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a697a77a",
   "metadata": {},
   "source": [
    "## üì• Part 1: Data Fetching & Storage System\n",
    "\n",
    "This section demonstrates the ETL pipeline that fetches NSE indices data from Yahoo Finance and stores it in a SQLite database with comprehensive quality controls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425f0890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Fetching NSE data for 13 indices...\n",
      "üìÖ Date range: 2025-01-01 to 2025-07-16\n",
      "\n",
      "üîÑ Processing Nifty 50 (^NSEI)... ‚úÖ 133 rows processed (0 new)\n",
      "üîÑ Processing Nifty Auto (^CNXAUTO)... ‚úÖ 132 rows processed (0 new)\n",
      "üîÑ Processing Nifty Bank (^NSEBANK)... ‚úÖ 133 rows processed (0 new)\n",
      "üîÑ Processing Nifty Auto (^CNXAUTO)... ‚úÖ 132 rows processed (0 new)\n",
      "üîÑ Processing Nifty Bank (^NSEBANK)... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['^CNXFIN']: YFPricesMissingError('possibly delisted; no price data found  (1d 2025-01-01 -> 2025-07-16)')\n",
      "['^CNXFIN']: YFPricesMissingError('possibly delisted; no price data found  (1d 2025-01-01 -> 2025-07-16)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 132 rows processed (0 new)\n",
      "üîÑ Processing Nifty Financial Services (^CNXFIN)... ‚ùå No data\n",
      "üîÑ Processing Nifty FMCG (^CNXFMCG)... ‚úÖ 132 rows processed (0 new)\n",
      "üîÑ Processing Nifty IT (^CNXIT)... ‚úÖ 132 rows processed (0 new)\n",
      "üîÑ Processing Nifty Media (^CNXMEDIA)... ‚úÖ 132 rows processed (0 new)\n",
      "üîÑ Processing Nifty IT (^CNXIT)... ‚úÖ 132 rows processed (0 new)\n",
      "üîÑ Processing Nifty Media (^CNXMEDIA)... ‚úÖ 132 rows processed (0 new)\n",
      "üîÑ Processing Nifty Metal (^CNXMETAL)... ‚úÖ 132 rows processed (0 new)\n",
      "üîÑ Processing Nifty Pharma (^CNXPHARMA)... ‚úÖ 132 rows processed (0 new)\n",
      "üîÑ Processing Nifty Metal (^CNXMETAL)... ‚úÖ 132 rows processed (0 new)\n",
      "üîÑ Processing Nifty Pharma (^CNXPHARMA)... ‚úÖ 133 rows processed (0 new)\n",
      "üîÑ Processing Nifty PSU Bank (^CNXPSUBANK)... ‚úÖ 132 rows processed (0 new)\n",
      "üîÑ Processing Nifty Realty (^CNXREALTY)... ‚úÖ 133 rows processed (0 new)\n",
      "üîÑ Processing Nifty PSU Bank (^CNXPSUBANK)... ‚úÖ 132 rows processed (0 new)\n",
      "üîÑ Processing Nifty Realty (^CNXREALTY)... ‚úÖ 132 rows processed (0 new)\n",
      "üîÑ Processing Nifty Private Bank (^CNXPRBANK)... ‚úÖ 132 rows processed (0 new)\n",
      "üîÑ Processing Nifty Private Bank (^CNXPRBANK)... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error 404: \n",
      "\n",
      "1 Failed download:\n",
      "['^CNXPRBANK']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "\n",
      "1 Failed download:\n",
      "['^CNXPRBANK']: YFTzMissingError('possibly delisted; no timezone found')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå No data\n",
      "üîÑ Processing Nifty Consumer Durables (^CNXCONSUMERDUR)... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error 404: \n",
      "\n",
      "1 Failed download:\n",
      "['^CNXCONSUMERDUR']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "\n",
      "1 Failed download:\n",
      "['^CNXCONSUMERDUR']: YFTzMissingError('possibly delisted; no timezone found')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå No data\n",
      "\n",
      "============================================================\n",
      "üìä SUMMARY\n",
      "============================================================\n",
      "‚úÖ Successful: 10\n",
      "‚ùå Failed: 3\n",
      "üìù New records inserted: 0\n",
      "üìä Total records in database: 37,167\n",
      "\n",
      "‚ùå Failed tickers requiring review:\n",
      "   ‚Ä¢ Nifty Financial Services (^CNXFIN)\n",
      "   ‚Ä¢ Nifty Private Bank (^CNXPRBANK)\n",
      "   ‚Ä¢ Nifty Consumer Durables (^CNXCONSUMERDUR)\n",
      "\n",
      "üí° Action: Check ticker symbols on Yahoo Finance\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "NSE Indices OHLC Data Fetcher\n",
    "============================\n",
    "Fetches OHLC data for NSE indices from Yahoo Finance and stores in SQLite database.\n",
    "\n",
    "Features:\n",
    "- Data validation (prevents negative/zero OHLC values)\n",
    "- Duplicate prevention with unique constraints\n",
    "- Error tracking for failed tickers\n",
    "\n",
    "Author: KO + GitHub Copilot:)\n",
    "\"\"\"\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sqlalchemy import create_engine, text\n",
    "import warnings\n",
    "\n",
    "# Suppress all warnings for clean output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "INDICES = {\n",
    "    'Nifty 50': '^NSEI',\n",
    "    'Nifty Auto': '^CNXAUTO',\n",
    "    'Nifty Bank': '^NSEBANK',\n",
    "    'Nifty Financial Services': '^CNXFIN',\n",
    "    'Nifty FMCG': '^CNXFMCG',\n",
    "    'Nifty IT': '^CNXIT',\n",
    "    'Nifty Media': '^CNXMEDIA',\n",
    "    'Nifty Metal': '^CNXMETAL',\n",
    "    'Nifty Pharma': '^CNXPHARMA',\n",
    "    'Nifty PSU Bank': '^CNXPSUBANK',\n",
    "    'Nifty Realty': '^CNXREALTY',\n",
    "    'Nifty Private Bank': '^CNXPRBANK',\n",
    "    'Nifty Consumer Durables': '^CNXCONSUMERDUR'\n",
    "}\n",
    "\n",
    "START_DATE = '2005-01-01'\n",
    "END_DATE = datetime.today().strftime('%Y-%m-%d')\n",
    "DATABASE_PATH = 'sqlite:///nse_data.db'\n",
    "\n",
    "# Create database table\n",
    "engine = create_engine(DATABASE_PATH)\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(text(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS nse_ohlc_prices (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            ticker TEXT NOT NULL,\n",
    "            name TEXT,\n",
    "            date DATE NOT NULL,\n",
    "            open REAL,\n",
    "            high REAL,\n",
    "            low REAL,\n",
    "            close REAL,\n",
    "            source TEXT DEFAULT 'yfinance',\n",
    "            frequency TEXT DEFAULT 'daily',\n",
    "            created_at TEXT,\n",
    "            updated_at TEXT,\n",
    "            UNIQUE(ticker, date, frequency, source)\n",
    "        )\n",
    "    \"\"\"))\n",
    "\n",
    "print(f\"üöÄ Fetching NSE data for {len(INDICES)} indices...\")\n",
    "print(f\"üìÖ Date range: {START_DATE} to {END_DATE}\\n\")\n",
    "\n",
    "# Initialize counters\n",
    "inserted_count = 0\n",
    "failed_count = 0\n",
    "failed_tickers = []\n",
    "invalid_count = 0\n",
    "\n",
    "# Process each ticker\n",
    "for name, ticker in INDICES.items():\n",
    "    print(f\"üîÑ Processing {name} ({ticker})...\", end=' ')\n",
    "    \n",
    "    try:\n",
    "        # Download data\n",
    "        df = yf.download(ticker, start=START_DATE, end=END_DATE, auto_adjust=True, progress=False)\n",
    "        \n",
    "        if df.empty:\n",
    "            print(\"‚ùå No data\")\n",
    "            failed_count += 1\n",
    "            failed_tickers.append(f\"{name} ({ticker})\")\n",
    "            continue\n",
    "        \n",
    "        # Handle MultiIndex columns\n",
    "        if isinstance(df.columns, pd.MultiIndex):\n",
    "            df.columns = df.columns.droplevel(1)\n",
    "        \n",
    "        # Prepare data for database\n",
    "        df = df.reset_index()\n",
    "        df['ticker'] = ticker\n",
    "        df['name'] = name\n",
    "        df['source'] = 'yfinance'\n",
    "        df['frequency'] = 'daily'\n",
    "        df['created_at'] = datetime.now().isoformat()\n",
    "        df['updated_at'] = datetime.now().isoformat()\n",
    "        \n",
    "        # Insert into database\n",
    "        rows_before = 0\n",
    "        with engine.connect() as conn:\n",
    "            result = conn.execute(text(\"SELECT COUNT(*) FROM nse_ohlc_prices WHERE ticker = :ticker\"), \n",
    "                                {'ticker': ticker})\n",
    "            rows_before = result.scalar()\n",
    "        \n",
    "        # Insert data with validation\n",
    "        with engine.begin() as conn:\n",
    "            for _, row in df.iterrows():\n",
    "                try:\n",
    "                    # Validate OHLC data - skip negative or zero values\n",
    "                    ohlc_values = [row.get('Open'), row.get('High'), row.get('Low'), row.get('Close')]\n",
    "                    if any(val is not None and not pd.isna(val) and val <= 0 for val in ohlc_values):\n",
    "                        invalid_count += 1\n",
    "                        continue  # Skip invalid data\n",
    "                    \n",
    "                    conn.execute(text(\"\"\"\n",
    "                        INSERT OR IGNORE INTO nse_ohlc_prices\n",
    "                        (ticker, name, date, open, high, low, close, source, frequency, created_at, updated_at)\n",
    "                        VALUES (:ticker, :name, :date, :open, :high, :low, :close, :source, :frequency, :created_at, :updated_at)\n",
    "                    \"\"\"), {\n",
    "                        'ticker': row['ticker'],\n",
    "                        'name': row['name'],\n",
    "                        'date': row['Date'].date(),\n",
    "                        'open': row.get('Open'),\n",
    "                        'high': row.get('High'),\n",
    "                        'low': row.get('Low'),\n",
    "                        'close': row.get('Close'),\n",
    "                        'source': row['source'],\n",
    "                        'frequency': row['frequency'],\n",
    "                        'created_at': row['created_at'],\n",
    "                        'updated_at': row['updated_at']\n",
    "                    })\n",
    "                except:\n",
    "                    pass  # Skip errors silently\n",
    "        \n",
    "        # Count new records\n",
    "        with engine.connect() as conn:\n",
    "            result = conn.execute(text(\"SELECT COUNT(*) FROM nse_ohlc_prices WHERE ticker = :ticker\"), \n",
    "                                {'ticker': ticker})\n",
    "            rows_after = result.scalar()\n",
    "        \n",
    "        new_records = rows_after - rows_before\n",
    "        inserted_count += new_records\n",
    "        print(f\"‚úÖ {len(df)} rows processed ({new_records} new)\")\n",
    "        \n",
    "    except Exception:\n",
    "        print(\"‚ùå Error\")\n",
    "        failed_count += 1\n",
    "        failed_tickers.append(f\"{name} ({ticker})\")\n",
    "\n",
    "# Final summary\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(f\"üìä SUMMARY\")\n",
    "print(f\"=\"*60)\n",
    "print(f\"‚úÖ Successful: {len(INDICES) - failed_count}\")\n",
    "print(f\"‚ùå Failed: {failed_count}\")\n",
    "print(f\"üìù New records inserted: {inserted_count}\")\n",
    "if invalid_count > 0:\n",
    "    print(f\"‚ö†Ô∏è  Invalid records skipped: {invalid_count} (negative/zero OHLC values)\")\n",
    "\n",
    "# Get total database count\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(\"SELECT COUNT(*) FROM nse_ohlc_prices\"))\n",
    "    total_records = result.scalar()\n",
    "print(f\"üìä Total records in database: {total_records:,}\")\n",
    "\n",
    "# Show failed tickers if any\n",
    "if failed_tickers:\n",
    "    print(f\"\\n‚ùå Failed tickers requiring review:\")\n",
    "    for ticker in failed_tickers:\n",
    "        print(f\"   ‚Ä¢ {ticker}\")\n",
    "    print(f\"\\nüí° Action: Check ticker symbols on Yahoo Finance\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebcd089",
   "metadata": {},
   "source": [
    "## üìä Part 2: Interactive Analytics Dashboard\n",
    "\n",
    "This section provides a comprehensive analytics dashboard with interactive widgets for:\n",
    "- **Returns Analysis**: Monthly/yearly performance matrices\n",
    "- **Correlation Analysis**: Multi-timeframe correlation matrices\n",
    "- **Data Quality Reporting**: Automated validation and issue detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc00da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd33fc0ead4e4c5d8789f9865e12ea89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(VBox(children=(HTML(value='<h3>Returns Analysis</h3>'), HBox(children=(VBox(children=(SelectMult‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ NSE Analytics Dashboard loaded successfully!\n",
      "üìã Features:\n",
      "  ‚Ä¢ Returns Analysis: Monthly/yearly returns matrices with data quality validation\n",
      "  ‚Ä¢ Correlation Analysis: Configurable correlation matrices with outlier detection\n",
      "  ‚Ä¢ Data Quality Checks: Automatic validation and cleaning of input data\n",
      "  ‚Ä¢ Interactive Interface: User-friendly widgets for parameter selection\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "NSE Analytics Dashboard - Interactive GUI for Stock Returns and Correlation Analysis\n",
    "\n",
    "This module provides a comprehensive dashboard for analyzing NSE indices performance\n",
    "with features for calculating returns matrices and correlation analysis.\n",
    "\n",
    "Key Features:\n",
    "- Returns analysis with configurable time periods\n",
    "- Correlation matrix calculation with multiple intervals\n",
    "- Interactive widgets for user-friendly data selection\n",
    "- Data quality validation and error handling\n",
    "- Optimized database queries for better performance\n",
    "\n",
    "Author: KO + GitHub Copilot:)\n",
    "\"\"\"\n",
    "\n",
    "# === IMPORTS ===\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np\n",
    "import logging\n",
    "from typing import List, Dict, Tuple, Optional, Union\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "# Configure logging for error tracking (but not display in notebook)\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Prevent logger messages from appearing in notebook output\n",
    "logger.propagate = False\n",
    "# Only log to file if a file handler is added, not to console\n",
    "for handler in logger.handlers[:]:\n",
    "    logger.removeHandler(handler)\n",
    "\n",
    "# NSE Indices mapping to Yahoo Finance ticker symbols\n",
    "INDICES = {\n",
    "    'Nifty 50': '^NSEI',\n",
    "    'Nifty Auto': '^CNXAUTO',\n",
    "    'Nifty Bank': '^NSEBANK',\n",
    "    'Nifty FMCG': '^CNXFMCG',\n",
    "    'Nifty IT': '^CNXIT',\n",
    "    'Nifty Media': '^CNXMEDIA',\n",
    "    'Nifty Metal': '^CNXMETAL',\n",
    "    'Nifty Pharma': '^CNXPHARMA',\n",
    "    'Nifty PSU Bank': '^CNXPSUBANK',\n",
    "    'Nifty Realty': '^CNXREALTY',\n",
    "    # Note: Some indices commented out due to data availability issues\n",
    "    # 'Nifty Financial Services': '^CNXFIN',\n",
    "    # 'Nifty Private Bank': '^CNXPRBANK',\n",
    "    # 'Nifty Consumer Durables': '^CNXCONSUMERDUR'\n",
    "}\n",
    "\n",
    "# Date range configuration\n",
    "DEFAULT_YEAR_RANGE = (2007, 2025)\n",
    "DEFAULT_LOOKBACK_DAYS = 365\n",
    "MONTHS_ORDER = ['Yearly', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "                'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "# === UTILITY FUNCTIONS ===\n",
    "def validate_data_quality(df: pd.DataFrame, ticker: str, index_name: str = None) -> Tuple[bool, List[str]]:\n",
    "    \"\"\"\n",
    "    Validate data quality for a given DataFrame and ticker.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing OHLC data\n",
    "        ticker: Ticker symbol being validated\n",
    "        index_name: Human-readable index name for better reporting\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (is_valid, list_of_issues)\n",
    "    \"\"\"\n",
    "    issues = []\n",
    "    display_name = index_name or ticker\n",
    "    \n",
    "    if df.empty:\n",
    "        issues.append(f\"No data available for {display_name}\")\n",
    "        return False, issues\n",
    "    \n",
    "    # Check for missing values\n",
    "    missing_data = df.isnull().sum()\n",
    "    if missing_data.any():\n",
    "        missing_info = {k: v for k, v in missing_data.to_dict().items() if v > 0}\n",
    "        if missing_info:\n",
    "            issues.append(f\"{display_name}: Missing data points - {missing_info}\")\n",
    "    \n",
    "    # Note: Negative/zero price validation is handled at database level during data ingestion\n",
    "    \n",
    "    # Check for data gaps (more than 7 consecutive days missing)\n",
    "    if 'date' in df.columns or df.index.name == 'date':\n",
    "        date_series = df.index if df.index.name == 'date' else df['date']\n",
    "        date_diff = date_series.diff()\n",
    "        large_gaps = (date_diff > pd.Timedelta(days=7)).sum()\n",
    "        if large_gaps > 0:\n",
    "            max_gap = date_diff.max().days\n",
    "            issues.append(f\"{display_name}: {large_gaps} large data gaps detected (>7 days), max gap: {max_gap} days\")\n",
    "    \n",
    "    # Check for extreme price movements (>50% in a single day)\n",
    "    if 'close' in df.columns:\n",
    "        daily_returns = df['close'].pct_change()\n",
    "        extreme_moves = (abs(daily_returns) > 0.5).sum()\n",
    "        if extreme_moves > 0:\n",
    "            max_move = abs(daily_returns).max() * 100\n",
    "            issues.append(f\"{display_name}: {extreme_moves} extreme price movements detected (>50% daily change), max: {max_move:.1f}%\")\n",
    "    \n",
    "    return len(issues) == 0, issues\n",
    "\n",
    "def create_collapsible_section(title: str, content: List[str], is_open: bool = False) -> None:\n",
    "    \"\"\"\n",
    "    Create a collapsible HTML section for displaying data quality information.\n",
    "    \n",
    "    Args:\n",
    "        title: Title for the collapsible section\n",
    "        content: List of content lines to display\n",
    "        is_open: Whether the section should be open by default\n",
    "    \"\"\"\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import HTML\n",
    "    \n",
    "    if not content:\n",
    "        return\n",
    "    \n",
    "    # Create HTML for collapsible content\n",
    "    content_html = \"<br>\".join([f\"‚Ä¢ {line}\" for line in content])\n",
    "    open_attr = \"open\" if is_open else \"\"\n",
    "    \n",
    "    html_content = f\"\"\"\n",
    "    <details {open_attr} style=\"margin-top: 10px; margin-bottom: 10px; padding: 10px; \n",
    "                                border: 1px solid #ddd; border-radius: 5px; background-color: #f9f9f9;\">\n",
    "        <summary style=\"font-weight: bold; cursor: pointer; padding: 5px; \n",
    "                       background-color: #e9e9e9; border-radius: 3px; margin-bottom: 10px;\">\n",
    "            {title} ({len(content)} items)\n",
    "        </summary>\n",
    "        <div style=\"margin-top: 10px; font-family: monospace; font-size: 12px; line-height: 1.4;\">\n",
    "            {content_html}\n",
    "        </div>\n",
    "    </details>\n",
    "    \"\"\"\n",
    "    \n",
    "    display(HTML(html_content))\n",
    "\n",
    "def build_query_parameters(tickers: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    Safely build SQL IN clause parameters for ticker list.\n",
    "    \n",
    "    Args:\n",
    "        tickers: List of ticker symbols\n",
    "        \n",
    "    Returns:\n",
    "        Formatted string for SQL IN clause\n",
    "    \"\"\"\n",
    "    return ','.join([f\"'{ticker}'\" for ticker in tickers])\n",
    "\n",
    "def calculate_monthly_returns(closes: pd.Series, year: int) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculate monthly and yearly returns for a given year.\n",
    "    \n",
    "    Args:\n",
    "        closes: Series of month-end closing prices\n",
    "        year: Year for calculation\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with monthly returns and yearly return\n",
    "    \"\"\"\n",
    "    returns = {}\n",
    "    \n",
    "    # Calculate monthly returns\n",
    "    monthly_pct_change = closes.pct_change(fill_method=None).dropna() * 100\n",
    "    \n",
    "    for i, month in enumerate(MONTHS_ORDER[1:], 1):  # Skip 'Yearly'\n",
    "        month_str = f\"{year}-{i:02d}\"\n",
    "        month_returns = monthly_pct_change.loc[\n",
    "            monthly_pct_change.index.strftime(\"%Y-%m\") == month_str\n",
    "        ]\n",
    "        returns[month] = round(month_returns.values[0], 2) if not month_returns.empty else np.nan\n",
    "    \n",
    "    # Calculate yearly return\n",
    "    dec_current = closes.loc[closes.index.strftime(\"%Y-%m\") == f\"{year}-12\"]\n",
    "    dec_previous = closes.loc[closes.index.strftime(\"%Y-%m\") == f\"{year-1}-12\"]\n",
    "    \n",
    "    if not dec_current.empty and not dec_previous.empty:\n",
    "        yearly_return = (dec_current.values[0] / dec_previous.values[0] - 1) * 100\n",
    "        returns['Yearly'] = round(yearly_return, 2)\n",
    "    else:\n",
    "        returns['Yearly'] = np.nan\n",
    "    \n",
    "    return returns\n",
    "\n",
    "# === WIDGET CREATION ===\n",
    "index_options = ['All'] + list(INDICES.keys())\n",
    "\n",
    "# Returns Tab Widgets\n",
    "index_multiselect_returns = widgets.SelectMultiple(\n",
    "    options=index_options,\n",
    "    value=['Nifty 50'],\n",
    "    description='Indices:',\n",
    "    rows=4,\n",
    "    disabled=False,\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "years_list = [str(y) for y in range(DEFAULT_YEAR_RANGE[1], DEFAULT_YEAR_RANGE[0] - 1, -1)]\n",
    "years_options = ['All'] + years_list\n",
    "years_multiselect = widgets.SelectMultiple(\n",
    "    options=years_options,\n",
    "    value=years_list[:5],  # Default to last 5 years\n",
    "    description='Years:',\n",
    "    rows=4,\n",
    "    disabled=False,\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "returns_calculate_button = widgets.Button(\n",
    "    description=\"Calculate Returns\",\n",
    "    style={'button_color': '#0072AA'},\n",
    "    icon=\"bar-chart\",\n",
    "    tooltip=\"Calculate and display returns matrix\"\n",
    ")\n",
    "returns_output = widgets.Output()\n",
    "\n",
    "# Correlation Tab Widgets  \n",
    "index_multiselect = widgets.SelectMultiple(\n",
    "    options=index_options,\n",
    "    rows=4,\n",
    "    value=['All'],\n",
    "    description='Indices:',\n",
    "    disabled=False,\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "interval_dropdown = widgets.Dropdown(\n",
    "    options=[('Daily', 'daily'), ('Monthly', 'monthly')],\n",
    "    value='daily',\n",
    "    description='Interval:',\n",
    "    disabled=False,\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "price_dropdown = widgets.Dropdown(\n",
    "    options=[('Open', 'open'), ('High', 'high'), ('Low', 'low'), ('Close', 'close')],\n",
    "    value='close',\n",
    "    description='Price Type:',\n",
    "    disabled=False,\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "start_date_picker = widgets.DatePicker(\n",
    "    description='Start Date:',\n",
    "    value=date.today() - timedelta(days=DEFAULT_LOOKBACK_DAYS),\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "end_date_picker = widgets.DatePicker(\n",
    "    description='End Date:',\n",
    "    value=date.today() - timedelta(days=1),\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "calculate_button = widgets.Button(\n",
    "    description=\"Calculate Correlation\",\n",
    "    style={'button_color': '#0072AA'},\n",
    "    icon=\"calculator\",\n",
    "    tooltip=\"Calculate correlation matrix\"\n",
    ")\n",
    "output = widgets.Output()\n",
    "\n",
    "# === LAYOUT CREATION ===\n",
    "returns_tab = widgets.VBox([\n",
    "    widgets.HTML(\"<h3>Returns Analysis</h3>\"),\n",
    "    widgets.HBox([\n",
    "        widgets.VBox([index_multiselect_returns], layout=widgets.Layout(width='33%')),\n",
    "        widgets.VBox([years_multiselect], layout=widgets.Layout(width='33%')),\n",
    "        widgets.VBox([returns_calculate_button], layout=widgets.Layout(width='33%', align_items='center'))\n",
    "    ]),\n",
    "    returns_output\n",
    "])\n",
    "\n",
    "correlation_tab = widgets.VBox([\n",
    "    widgets.HTML(\"<h3>Correlation Matrix</h3>\"),\n",
    "    widgets.HBox([index_multiselect, interval_dropdown, price_dropdown, start_date_picker, end_date_picker, calculate_button]),\n",
    "    output\n",
    "])\n",
    "\n",
    "tabs = widgets.Tab(children=[returns_tab, correlation_tab])\n",
    "tabs.set_title(0, 'Returns Analysis')\n",
    "tabs.set_title(1, 'Correlation Matrix')\n",
    "\n",
    "display(tabs)\n",
    "\n",
    "# === DATABASE CONNECTION ===\n",
    "try:\n",
    "    engine = create_engine('sqlite:///nse_data.db', echo=False)\n",
    "    # Test connection\n",
    "    test_query = \"SELECT COUNT(*) FROM nse_ohlc_prices LIMIT 1\"\n",
    "    pd.read_sql(test_query, engine)\n",
    "    # Logger message will not appear in notebook output\n",
    "    logger.info(\"Database connection established successfully\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Database connection failed: {e}\")\n",
    "    print(\"‚ö†Ô∏è  Database connection failed. Please run the data fetching section first to create the database.\")\n",
    "\n",
    "# === EVENT HANDLERS ===\n",
    "def on_returns_calculate_clicked(button):\n",
    "    \"\"\"\n",
    "    Handle returns calculation button click event.\n",
    "    \n",
    "    Args:\n",
    "        button: Button widget that triggered the event\n",
    "    \"\"\"\n",
    "    with returns_output:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        try:\n",
    "            # Input validation and processing\n",
    "            selected_indices = list(index_multiselect_returns.value)\n",
    "            if 'All' in selected_indices:\n",
    "                selected_indices = list(INDICES.keys())\n",
    "            \n",
    "            if not selected_indices:\n",
    "                print(\"‚ùå Please select at least one index.\")\n",
    "                return\n",
    "\n",
    "            years_selected = list(years_multiselect.value)\n",
    "            if 'All' in years_selected:\n",
    "                years_selected = years_list\n",
    "            \n",
    "            if not years_selected:\n",
    "                print(\"‚ùå Please select at least one year.\")\n",
    "                return\n",
    "\n",
    "            # Process years and build query parameters\n",
    "            years_selected_int = sorted([int(y) for y in years_selected], reverse=True)\n",
    "            min_year, max_year = min(years_selected_int), max(years_selected_int)\n",
    "            query_start = f\"{min_year-1}-12-01\"\n",
    "            query_end = f\"{max_year}-12-31\"\n",
    "            \n",
    "            selected_tickers = [INDICES[name] for name in selected_indices]\n",
    "            \n",
    "            \n",
    "            # Optimized single query for all data\n",
    "            query = f\"\"\"\n",
    "                SELECT ticker, name, date, close \n",
    "                FROM nse_ohlc_prices \n",
    "                WHERE ticker IN ({build_query_parameters(selected_tickers)})\n",
    "                AND date >= '{query_start}' AND date <= '{query_end}'\n",
    "                ORDER BY ticker, date\n",
    "            \"\"\"\n",
    "            \n",
    "            df = pd.read_sql(query, engine, parse_dates=['date'])\n",
    "            \n",
    "            if df.empty:\n",
    "                print(\"‚ùå No data found for selected indices and years.\")\n",
    "                return\n",
    "            \n",
    "            # Data quality validation\n",
    "            data_issues = []\n",
    "            for ticker in selected_tickers:\n",
    "                ticker_data = df[df['ticker'] == ticker]\n",
    "                # Find the index name for this ticker\n",
    "                index_name = next((name for name, tick in INDICES.items() if tick == ticker), ticker)\n",
    "                is_valid, issues = validate_data_quality(ticker_data, ticker, index_name)\n",
    "                if not is_valid:\n",
    "                    data_issues.extend(issues)\n",
    "            \n",
    "            df = df.set_index('date').sort_index()\n",
    "            \n",
    "            if len(selected_indices) == 1:\n",
    "                # Single index analysis with monthly breakdown\n",
    "                index_name = selected_indices[0]\n",
    "                ticker = INDICES[index_name]\n",
    "                index_data = df[df['ticker'] == ticker]['close']\n",
    "                \n",
    "                if index_data.empty:\n",
    "                    print(f\"‚ùå No data available for {index_name}\")\n",
    "                    return\n",
    "                \n",
    "                monthly_close = index_data.resample('ME').last()\n",
    "                \n",
    "                # Create returns grid\n",
    "                grid = pd.DataFrame(index=[str(y) for y in years_selected_int], columns=MONTHS_ORDER)\n",
    "                \n",
    "                for year in years_selected_int:\n",
    "                    year_closes = monthly_close.loc[\n",
    "                        (monthly_close.index >= pd.Timestamp(f\"{year-1}-12-01\")) &\n",
    "                        (monthly_close.index <= pd.Timestamp(f\"{year}-12-31\"))\n",
    "                    ]\n",
    "                    \n",
    "                    if year_closes.empty:\n",
    "                        continue\n",
    "                    \n",
    "                    # Handle current month exclusion if incomplete\n",
    "                    if (year_closes.index.max().year == date.today().year and \n",
    "                        year_closes.index.max().month == date.today().month and\n",
    "                        date.today().day < pd.Period(year_closes.index.max(), freq='M').days_in_month):\n",
    "                        year_closes = year_closes.iloc[:-1]\n",
    "                    \n",
    "                    if not year_closes.empty:\n",
    "                        returns_dict = calculate_monthly_returns(year_closes, year)\n",
    "                        for month, return_val in returns_dict.items():\n",
    "                            grid.loc[str(year), month] = return_val\n",
    "                \n",
    "                # Clean and display grid\n",
    "                grid = grid.dropna(how='all').dropna(axis=1, how='all')\n",
    "                grid_numeric = grid.apply(pd.to_numeric, errors='coerce')\n",
    "                \n",
    "                display(\n",
    "                    grid_numeric.style\n",
    "                    .format(\"{:.2f}%\", na_rep=\"‚Äî\")\n",
    "                    .background_gradient(cmap=\"RdYlGn\", axis=None, vmin=-10, vmax=10)\n",
    "                    .set_caption(f\"{index_name} - Monthly Returns Analysis\")\n",
    "                    .set_table_styles([\n",
    "                        {'selector': 'caption', 'props': [('font-size', '16px'), ('font-weight', 'bold')]}\n",
    "                    ])\n",
    "                )\n",
    "                \n",
    "                # Display data quality issues in collapsible section\n",
    "                if data_issues:\n",
    "                    create_collapsible_section(\"‚ö†Ô∏è Data Quality Issues\", data_issues, is_open=False)\n",
    "                \n",
    "            else:\n",
    "                # Multiple indices - yearly comparison\n",
    "                yearly_grid = pd.DataFrame(index=[str(y) for y in years_selected_int], \n",
    "                                         columns=selected_indices)\n",
    "                \n",
    "                for index_name in selected_indices:\n",
    "                    ticker = INDICES[index_name]\n",
    "                    index_data = df[df['ticker'] == ticker]['close']\n",
    "                    \n",
    "                    if index_data.empty:\n",
    "                        continue\n",
    "                    \n",
    "                    monthly_close = index_data.resample('ME').last()\n",
    "                    \n",
    "                    for year in years_selected_int:\n",
    "                        year_closes = monthly_close.loc[\n",
    "                            (monthly_close.index >= pd.Timestamp(f\"{year-1}-12-01\")) &\n",
    "                            (monthly_close.index <= pd.Timestamp(f\"{year}-12-31\"))\n",
    "                        ]\n",
    "                        \n",
    "                        if year_closes.empty:\n",
    "                            yearly_grid.loc[str(year), index_name] = np.nan\n",
    "                            continue\n",
    "                        \n",
    "                        returns_dict = calculate_monthly_returns(year_closes, year)\n",
    "                        yearly_grid.loc[str(year), index_name] = returns_dict.get('Yearly', np.nan)\n",
    "                \n",
    "                # Clean and display grid\n",
    "                yearly_grid = yearly_grid.dropna(how='all')\n",
    "                yearly_grid_numeric = yearly_grid.apply(pd.to_numeric, errors='coerce')\n",
    "                \n",
    "            \n",
    "                display(\n",
    "                    yearly_grid_numeric.style\n",
    "                    .format(\"{:.2f}%\", na_rep=\"‚Äî\")\n",
    "                    .background_gradient(cmap=\"RdYlGn\", axis=None, vmin=-20, vmax=30)\n",
    "                    .set_caption(\"Yearly Returns Comparison Across Indices\")\n",
    "                    .set_table_styles([\n",
    "                        {'selector': 'caption', 'props': [('font-size', '16px'), ('font-weight', 'bold')]}\n",
    "                    ])\n",
    "                )\n",
    "                \n",
    "                # Display data quality issues in collapsible section\n",
    "                if data_issues:\n",
    "                    create_collapsible_section(\"‚ö†Ô∏è Data Quality Issues\", data_issues, is_open=False)\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in returns calculation: {e}\")\n",
    "            print(f\"‚ùå Error occurred during calculation: {str(e)}\")\n",
    "            print(\"Please check your data and try again.\")\n",
    "\n",
    "def on_correlation_calculate_clicked(button):\n",
    "    \"\"\"\n",
    "    Handle correlation calculation button click event.\n",
    "    \n",
    "    Args:\n",
    "        button: Button widget that triggered the event\n",
    "    \"\"\"\n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        try:\n",
    "            # Input validation\n",
    "            selected_names = list(index_multiselect.value)\n",
    "            if 'All' in selected_names:\n",
    "                selected_names = list(INDICES.keys())\n",
    "            \n",
    "            if not selected_names:\n",
    "                print(\"‚ùå Please select at least one index.\")\n",
    "                return\n",
    "            \n",
    "            selected_tickers = [INDICES[name] for name in selected_names]\n",
    "            interval = interval_dropdown.value\n",
    "            price_col = price_dropdown.value\n",
    "            start = pd.Timestamp(start_date_picker.value)\n",
    "            end = pd.Timestamp(end_date_picker.value)\n",
    "            \n",
    "            if start >= end:\n",
    "                print(\"‚ùå Start date must be before end date.\")\n",
    "                return\n",
    "            \n",
    "            \n",
    "            # Check data availability and adjust dates if necessary\n",
    "            range_query = f\"\"\"\n",
    "                SELECT ticker, MIN(date) as min_date, MAX(date) as max_date \n",
    "                FROM nse_ohlc_prices \n",
    "                WHERE ticker IN ({build_query_parameters(selected_tickers)})\n",
    "                GROUP BY ticker\n",
    "            \"\"\"\n",
    "            \n",
    "            ranges = pd.read_sql(range_query, engine, parse_dates=['min_date', 'max_date'])\n",
    "            \n",
    "            if ranges.empty:\n",
    "                print(\"‚ùå No data available for selected indices.\")\n",
    "                return\n",
    "            \n",
    "            # Find overlapping date range\n",
    "            max_start = ranges['min_date'].max()\n",
    "            min_end = ranges['max_date'].min()\n",
    "            \n",
    "            adjusted = False\n",
    "            original_start, original_end = start, end\n",
    "            \n",
    "            if start < max_start:\n",
    "                start = max_start\n",
    "                start_date_picker.value = start.to_pydatetime().date()\n",
    "                adjusted = True\n",
    "                \n",
    "            if end > min_end:\n",
    "                end = min_end\n",
    "                end_date_picker.value = end.to_pydatetime().date()\n",
    "                adjusted = True\n",
    "            \n",
    "            if adjusted:\n",
    "                print(f\"‚ö†Ô∏è Date range adjusted to available data: {start.date()} to {end.date()}\")\n",
    "            \n",
    "            # Fetch OHLC data\n",
    "            data_query = f\"\"\"\n",
    "                SELECT ticker, name, date, {price_col} \n",
    "                FROM nse_ohlc_prices \n",
    "                WHERE ticker IN ({build_query_parameters(selected_tickers)})\n",
    "                AND date >= '{start.date()}' AND date <= '{end.date()}'\n",
    "                ORDER BY date, ticker\n",
    "            \"\"\"\n",
    "            \n",
    "            df = pd.read_sql(data_query, engine, parse_dates=['date'])\n",
    "            \n",
    "            if df.empty:\n",
    "                print(\"‚ùå No data found for the selected parameters.\")\n",
    "                return\n",
    "            \n",
    "            \n",
    "            # Create price matrix\n",
    "            prices = df.pivot(index='date', columns='name', values=price_col)\n",
    "            \n",
    "            # Collect data quality information\n",
    "            quality_issues = []\n",
    "            \n",
    "            # Handle missing data\n",
    "            missing_pct = (prices.isnull().sum() / len(prices) * 100).round(2)\n",
    "            if missing_pct.any():\n",
    "                for idx, pct in missing_pct[missing_pct > 0].items():\n",
    "                    quality_issues.append(f\"{idx}: {pct}% missing data\")\n",
    "            \n",
    "            # Forward fill missing values\n",
    "            prices = prices.ffill()\n",
    "            \n",
    "            # Remove columns with too much missing data (>20%)\n",
    "            valid_columns = missing_pct[missing_pct <= 20].index\n",
    "            if len(valid_columns) < len(prices.columns):\n",
    "                removed_cols = set(prices.columns) - set(valid_columns)\n",
    "                for col in removed_cols:\n",
    "                    quality_issues.append(f\"{col}: Removed due to >20% missing data ({missing_pct[col]:.1f}%)\")\n",
    "                prices = prices[valid_columns]\n",
    "            \n",
    "            if prices.empty:\n",
    "                print(\"‚ùå No valid data remaining after quality checks.\")\n",
    "                return\n",
    "            \n",
    "            # Resample for monthly analysis\n",
    "            if interval == 'monthly':\n",
    "                prices = prices.resample('ME').last()\n",
    "                # Remove current month if incomplete\n",
    "                if end.day < pd.Period(end, freq='M').days_in_month:\n",
    "                    prices = prices.iloc[:-1]\n",
    "            \n",
    "            # Calculate returns\n",
    "            returns = prices.pct_change().dropna(how='all')\n",
    "            returns.columns.name = None\n",
    "            \n",
    "            if returns.empty:\n",
    "                print(\"‚ùå Insufficient data to calculate returns.\")\n",
    "                return\n",
    "            \n",
    "            # Remove extreme outliers (>3 standard deviations)\n",
    "            outlier_info = []\n",
    "            for col in returns.columns:\n",
    "                mean_return = returns[col].mean()\n",
    "                std_return = returns[col].std()\n",
    "                outlier_threshold = 3 * std_return\n",
    "                outliers = abs(returns[col] - mean_return) > outlier_threshold\n",
    "                if outliers.any():\n",
    "                    outlier_count = outliers.sum()\n",
    "                    max_outlier = abs(returns[col] - mean_return).max()\n",
    "                    outlier_info.append(f\"{col}: {outlier_count} outliers removed (max deviation: {max_outlier:.3f})\")\n",
    "                    returns.loc[outliers, col] = np.nan\n",
    "            \n",
    "            quality_issues.extend(outlier_info)\n",
    "            \n",
    "            # Calculate correlation matrix\n",
    "            corr = returns.corr()\n",
    "            \n",
    "           \n",
    "            display(\n",
    "                corr.style\n",
    "                .background_gradient(cmap=\"RdYlGn\", axis=None, vmin=-1, vmax=1)\n",
    "                .format(\"{:.3f}\")\n",
    "                .set_caption(f\"{interval.title()} Price Correlation Matrix ({price_col.title()} Prices)\")\n",
    "                .set_table_styles([\n",
    "                    {'selector': 'caption', 'props': [('font-size', '16px'), ('font-weight', 'bold')]},\n",
    "                    {'selector': 'th', 'props': [('text-align', 'center')]},\n",
    "                    {'selector': 'td', 'props': [('text-align', 'center')]}\n",
    "                ])\n",
    "            )\n",
    "            \n",
    "            # Display data quality issues in collapsible section\n",
    "            if quality_issues:\n",
    "                create_collapsible_section(\"üìä Data Quality Report\", quality_issues, is_open=False)\n",
    "            \n",
    "            return corr\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in correlation calculation: {e}\")\n",
    "            print(f\"‚ùå Error occurred during calculation: {str(e)}\")\n",
    "            print(\"Please check your inputs and try again.\")\n",
    "\n",
    "# === BIND EVENT HANDLERS ===\n",
    "returns_calculate_button.on_click(on_returns_calculate_clicked)\n",
    "calculate_button.on_click(on_correlation_calculate_clicked)\n",
    "\n",
    "print(\"üöÄ NSE Analytics Dashboard loaded successfully!\")\n",
    "print(\"üìã Features:\")\n",
    "print(\"  ‚Ä¢ Returns Analysis: Monthly/yearly returns matrices with data quality validation\")\n",
    "print(\"  ‚Ä¢ Correlation Analysis: Configurable correlation matrices with outlier detection\")\n",
    "print(\"  ‚Ä¢ Data Quality Checks: Automatic validation and cleaning of input data\")\n",
    "print(\"  ‚Ä¢ Interactive Interface: User-friendly widgets for parameter selection\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
